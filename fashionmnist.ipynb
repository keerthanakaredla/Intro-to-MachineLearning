{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashionmnist.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMRUMbAz+h8TC/BBdIqwa0C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keerthanakaredla/Intro-to-MachineLearning/blob/master/fashionmnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJTi90LdovG1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ab63324-d332-4638-aa3b-24c31eb1d8e8"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9T3pH-6o5UD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = tf.keras.datasets.fashion_mnist"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8yxr_-CpOJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "14c807b8-48c1-4038-b7fd-379d78a9ff90"
      },
      "source": [
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5b0iPLrpeTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aff5c613-744b-4d0f-d744-6fe2df02db18"
      },
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(training_images[0])\n",
        "print(training_labels[0])\n",
        "print(training_images[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n",
            "[[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.         0.05098039 0.28627451\n",
            "  0.         0.         0.00392157 0.01568627 0.         0.         0.         0.         0.00392157 0.00392157 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01176471 0.         0.14117647 0.53333333 0.49803922\n",
            "  0.24313725 0.21176471 0.         0.         0.         0.00392157 0.01176471 0.01568627 0.         0.         0.01176471]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.4        0.8        0.69019608\n",
            "  0.5254902  0.56470588 0.48235294 0.09019608 0.         0.         0.         0.         0.04705882 0.03921569 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.60784314 0.9254902  0.81176471\n",
            "  0.69803922 0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608 0.30196078 0.50980392 0.28235294 0.05882353]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.         0.27058824 0.81176471 0.8745098  0.85490196\n",
            "  0.84705882 0.84705882 0.63921569 0.49803922 0.4745098  0.47843137 0.57254902 0.55294118 0.34509804 0.6745098  0.25882353]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.00392157 0.00392157 0.         0.78431373 0.90980392 0.90980392 0.91372549\n",
            "  0.89803922 0.8745098  0.8745098  0.84313725 0.83529412 0.64313725 0.49803922 0.48235294 0.76862745 0.89803922 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.71764706 0.88235294 0.84705882 0.8745098\n",
            "  0.89411765 0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667 0.8745098  0.96078431 0.67843137 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.75686275 0.89411765 0.85490196 0.83529412\n",
            "  0.77647059 0.70588235 0.83137255 0.82352941 0.82745098 0.83529412 0.8745098  0.8627451  0.95294118 0.79215686 0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.00392157 0.01176471 0.         0.04705882 0.85882353 0.8627451  0.83137255 0.85490196\n",
            "  0.75294118 0.6627451  0.89019608 0.81568627 0.85490196 0.87843137 0.83137255 0.88627451 0.77254902 0.81960784 0.20392157]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.02352941 0.         0.38823529 0.95686275 0.87058824 0.8627451  0.85490196\n",
            "  0.79607843 0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451  0.96078431 0.46666667 0.65490196 0.21960784]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.01568627 0.         0.         0.21568627 0.9254902  0.89411765 0.90196078 0.89411765\n",
            "  0.94117647 0.90980392 0.83529412 0.85490196 0.8745098  0.91764706 0.85098039 0.85098039 0.81960784 0.36078431 0.        ]\n",
            " [0.         0.         0.00392157 0.01568627 0.02352941 0.02745098 0.00784314 0.         0.         0.         0.         0.         0.92941176 0.88627451 0.85098039 0.8745098  0.87058824\n",
            "  0.85882353 0.87058824 0.86666667 0.84705882 0.8745098  0.89803922 0.84313725 0.85490196 1.         0.30196078 0.        ]\n",
            " [0.         0.01176471 0.         0.         0.         0.         0.         0.         0.         0.24313725 0.56862745 0.8        0.89411765 0.81176471 0.83529412 0.86666667 0.85490196\n",
            "  0.81568627 0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725 0.87843137 0.95686275 0.62352941 0.        ]\n",
            " [0.         0.         0.         0.         0.07058824 0.17254902 0.32156863 0.41960784 0.74117647 0.89411765 0.8627451  0.87058824 0.85098039 0.88627451 0.78431373 0.80392157 0.82745098\n",
            "  0.90196078 0.87843137 0.91764706 0.69019608 0.7372549  0.98039216 0.97254902 0.91372549 0.93333333 0.84313725 0.        ]\n",
            " [0.         0.22352941 0.73333333 0.81568627 0.87843137 0.86666667 0.87843137 0.81568627 0.8        0.83921569 0.81568627 0.81960784 0.78431373 0.62352941 0.96078431 0.75686275 0.80784314\n",
            "  0.8745098  1.         1.         0.86666667 0.91764706 0.86666667 0.82745098 0.8627451  0.90980392 0.96470588 0.        ]\n",
            " [0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098 0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451  0.94117647 0.31372549 0.58823529 1.         0.89803922\n",
            "  0.86666667 0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784 0.87058824 0.89411765 0.88235294 0.        ]\n",
            " [0.38431373 0.91372549 0.77647059 0.82352941 0.87058824 0.89803922 0.89803922 0.91764706 0.97647059 0.8627451  0.76078431 0.84313725 0.85098039 0.94509804 0.25490196 0.28627451 0.41568627\n",
            "  0.45882353 0.65882353 0.85882353 0.86666667 0.84313725 0.85098039 0.8745098  0.8745098  0.87843137 0.89803922 0.11372549]\n",
            " [0.29411765 0.8        0.83137255 0.8        0.75686275 0.80392157 0.82745098 0.88235294 0.84705882 0.7254902  0.77254902 0.80784314 0.77647059 0.83529412 0.94117647 0.76470588 0.89019608\n",
            "  0.96078431 0.9372549  0.8745098  0.85490196 0.83137255 0.81960784 0.87058824 0.8627451  0.86666667 0.90196078 0.2627451 ]\n",
            " [0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902 0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569 0.85882353 0.86666667 0.8627451  0.9254902  0.88235294\n",
            "  0.84705882 0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098  0.70980392 0.80392157 0.80784314 0.45098039]\n",
            " [0.         0.47843137 0.85882353 0.75686275 0.70196078 0.67058824 0.71764706 0.76862745 0.8        0.82352941 0.83529412 0.81176471 0.82745098 0.82352941 0.78431373 0.76862745 0.76078431\n",
            "  0.74901961 0.76470588 0.74901961 0.77647059 0.75294118 0.69019608 0.61176471 0.65490196 0.69411765 0.82352941 0.36078431]\n",
            " [0.         0.         0.29019608 0.74117647 0.83137255 0.74901961 0.68627451 0.6745098  0.68627451 0.70980392 0.7254902  0.7372549  0.74117647 0.7372549  0.75686275 0.77647059 0.8\n",
            "  0.81960784 0.82352941 0.82352941 0.82745098 0.7372549  0.7372549  0.76078431 0.75294118 0.84705882 0.66666667 0.        ]\n",
            " [0.00784314 0.         0.         0.         0.25882353 0.78431373 0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118 0.95686275 0.86666667 0.8627451  0.75686275 0.74901961\n",
            "  0.70196078 0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353 0.38823529 0.22745098 0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.15686275 0.23921569 0.17254902 0.28235294 0.16078431 0.1372549  0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIalXsMNphSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkj3wUEVrUI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSkmIgP8rXxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "254a54ac-e1eb-42ca-f10e-1e0efa9241bf"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=15)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3976 - accuracy: 0.8601\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3929 - accuracy: 0.8611\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3888 - accuracy: 0.8626\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3843 - accuracy: 0.8640\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3811 - accuracy: 0.8654\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3774 - accuracy: 0.8673\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3740 - accuracy: 0.8681\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3708 - accuracy: 0.8693\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3682 - accuracy: 0.8695\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3646 - accuracy: 0.8716\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3623 - accuracy: 0.8717\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3591 - accuracy: 0.8727\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3569 - accuracy: 0.8743\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3543 - accuracy: 0.8745\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3517 - accuracy: 0.8764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f633262c2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xanZ3BHr8w2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5c64beae-8fd5-4015-ff0d-5d07fa1e7f28"
      },
      "source": [
        "model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8575\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.39957448840141296, 0.8575000166893005]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7C3rXCvsXgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00edcd25-f7aa-4493-fdc7-a92cfa1d2b41"
      },
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7.9049222e-08 5.8563909e-09 3.6685758e-06 3.0785836e-06 2.3582020e-06 8.2903601e-02 2.9412520e-06 1.3015905e-01 3.0141536e-03 7.8391105e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b6ivaEmt3_S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba0c6ba1-7d7b-463a-f174-5837630c8bdb"
      },
      "source": [
        "print(test_labels[0])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63CqAWOpt6h-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "08109c71-81b1-4bf1-e887-f55484c1bbe9"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.1856\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0749\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0480\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0348\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0263\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0686\n",
            "[2.8114162e-09 2.8385567e-09 2.8670868e-08 2.3836392e-07 2.1648282e-14 1.4512695e-10 3.7624763e-14 9.9999964e-01 2.0010749e-09 1.1313818e-07]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtTwl4hv0Ebh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "063f4e16-339c-4d4b-96c6-9ad2ca7f7aaf"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=30)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2602\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1132\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0782\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0595\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0447\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0359\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0288\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0234\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0189\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0166\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0131\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0108\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0103\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0089\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0090\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0077\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0063\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0067\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0068\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0054\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0051\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0052\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0049\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0020\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0062\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0040\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0042\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0031\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0064\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0022\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.1241\n",
            "[2.1399219e-22 6.9854240e-21 8.4227167e-14 6.8005063e-13 9.9709859e-29 2.0795504e-29 3.9621656e-27 1.0000000e+00 6.1533264e-17 3.5712438e-17]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwELYU7o0TQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "a2f29c03-8fcf-472f-bcff-423051682021"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2023\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0803\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0523\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0372\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0282\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0749\n",
            "[2.0356454e-09 6.8281630e-10 3.1204213e-08 5.4716706e-06 9.5141690e-13 3.0337044e-09 1.8911108e-13 9.9999440e-01 3.5012160e-09 1.5624843e-07]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISNyaO0l0uDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "d8187712-0387-4c13-8474-829b0bfd4cd0"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('loss')<0.4):\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.4750\n",
            "Epoch 2/5\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.3577\n",
            "Reached 60% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3581\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6333817438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdnfQSsY1D0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}